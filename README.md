# Machine Learning Ethics References
References about Machine Learning and Data Science discrimination, bias, ethics.


##Discussion
* [AI Ethics on Reddit](https://www.reddit.com/r/AIethics/)
* [(HN)Attacking discrimination with smarter machine learning](https://news.ycombinator.com/item?id=13004790)
* [(HN)Cathy O’Neil on Weapons of Math Destruction](https://news.ycombinator.com/item?id=12642432)
* [(HN) on Neural Net Trained on Mugshots Predicts Criminals](https://news.ycombinator.com/item?id=13034116)

##Podcast

* [EconTalk Episode with Cathy O'Neil](http://www.econtalk.org/archives/2016/10/cathy_oneil_on_1.html)

##Videos

* [Ethics of Artificial Intelligence conference NYU 2016](https://livestream.com/nyu-tv/ethicsofAI/)

##Papers 

* [Bias in Computer Systems](https://www.nyu.edu/projects/nissenbaum/papers/biasincomputers.pdf)
* [Equality of Opportunity in Supervised Learning](https://drive.google.com/file/d/0B-wQVEjH9yuhanpyQjUwQS1JOTQ/view)
* [Using sensitive personal data may be necessary
for avoiding discrimination in data-driven decision
models](https://sites.google.com/site/zliobaitefiles2/Zliobaite_fair_regression.pdf?attredirects=1)
* [The Ethics of Artificial Intelligence](http://www.nickbostrom.com/ethics/artificial-intelligence.pdf)
* [Automated Inference on Criminality using Face Images](https://arxiv.org/abs/1611.04135)

##Books

* [Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy](https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815/ref=sr_1_1?ie=UTF8&qid=1479818920&sr=8-1&keywords=Weapons-Math-Destruction-Increases-Inequality)

##Articles
* [Neural Net Trained on Mugshots Predicts Criminals](https://www.technologyreview.com/s/602955/neural-network-learns-to-identify-criminals-by-their-faces/)
* [Attacking discrimination with smarter machine learning](http://research.google.com/bigpicture/attacking-discrimination-in-ml/)
* [The Ethical Data Scientis](http://www.slate.com/articles/technology/future_tense/2016/02/how_to_bring_better_ethics_to_data_science.html)
* [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
* [Are Machines Biased, or Are We Biased Against Machines?](http://alex.miller.im/posts/are-we-biased-against-machines-propublica-recidivism/)
* [Artificial Intelligence’s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html)
* [Buyer Beware: A hard look at police ‘threat scores.’](https://www.equalfuture.us/2016/01/14/buyer-beware-police-threat-scores/)
* [Computer and Information Ethics](http://plato.stanford.edu/entries/ethics-computer/)
* [Social Networking and Ethics](http://plato.stanford.edu/entries/ethics-social-networking/)
* [Internet Research Ethics](http://plato.stanford.edu/entries/ethics-internet-research/)
* [Search Engines and Ethics](http://plato.stanford.edu/entries/ethics-search/)

##Others
* ["RoboCop” assignment Columbia University NYPD’s “Stop, Question and Frisk” records](http://columbialion.com/colorcode-statement-on-coms-4771-stop-and-frisk-competition/)
* [Professor Satyen Kale Responds to ‘RoboCop’ Machine Learning Assignment](http://columbialion.com/professor-satyen-kale-responds-to-robocop-ml-assignment/)
