# Machine Learning Ethics References
References about Machine Learning and Data Science discrimination, bias, ethics.


## Discussion
* [AI Ethics on Reddit](https://www.reddit.com/r/AIethics/)
* [(HN) Attacking discrimination with smarter machine learning](https://news.ycombinator.com/item?id=13004790)
* [(HN) Cathy O’Neil on Weapons of Math Destruction](https://news.ycombinator.com/item?id=12642432)
* [(HN) on Neural Net Trained on Mugshots Predicts Criminals](https://news.ycombinator.com/item?id=13034116)
* [(HN) Justice.exe: Bias in Algorithmic sentencing ](https://news.ycombinator.com/item?id=14285116)

## Podcast

* [EconTalk Episode with Cathy O'Neil](http://www.econtalk.org/archives/2016/10/cathy_oneil_on_1.html)
* [Machine Ethic Podcasts](http://machine-ethics.net/podcast/)

## Videos

* [Ethics of Artificial Intelligence conference NYU 2016](https://livestream.com/nyu-tv/ethicsofAI/)
* [A Story of Discrimination and Unfairness - Aylin Caliskan 33c3 2016](https://media.ccc.de/v/33c3-8026-a_story_of_discrimination_and_unfairness)
* [AI Now 2017 Symposium](https://www.youtube.com/watch?v=npL_UsK_npE)

## Papers 

* [Bias in Computer Systems](https://www.nyu.edu/projects/nissenbaum/papers/biasincomputers.pdf)
* [Equality of Opportunity in Supervised Learning](https://drive.google.com/file/d/0B-wQVEjH9yuhanpyQjUwQS1JOTQ/view)
* [Using sensitive personal data may be necessary for avoiding discrimination in data-driven decision models](https://sites.google.com/site/zliobaitefiles2/Zliobaite_fair_regression.pdf?attredirects=1)
* [The Ethics of Artificial Intelligence](http://www.nickbostrom.com/ethics/artificial-intelligence.pdf)
* [Automated Inference on Criminality using Face Images](https://arxiv.org/abs/1611.04135)
* [Semantics derived automatically from language corpora contain human-like biases](http://opus.bath.ac.uk/55288/)
* [European Union regulations on algorithmic decision-making and a "right to explanation"](https://arxiv.org/abs/1606.08813)
* [Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints](https://homes.cs.washington.edu/~my89/publications/bias.pdf)
* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://arxiv.org/abs/1607.06520)
* [Deep neural networks are more accurate than humans at detecting sexual orientation from facial images.](https://osf.io/zn79k/)

## Books

* [Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy](https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815/ref=sr_1_1?ie=UTF8&qid=1479818920&sr=8-1&keywords=Weapons-Math-Destruction-Increases-Inequality)

## Articles
* [Algorithms: AI’s creepy control must be open to inspection](https://www.theguardian.com/commentisfree/2017/jan/01/algorithms-ai-artificial-intelligence-facebook-accountability)
* [AI watchdog needed to regulate automated decision-making, say experts](https://www.theguardian.com/technology/2017/jan/27/ai-artificial-intelligence-watchdog-needed-to-prevent-discriminatory-automated-decisions)
* [Scholars Delve Deeper Into The Ethics Of Artificial Intelligence](http://www.npr.org/sections/alltechconsidered/2016/11/21/502905772/scholars-delve-deeper-into-the-ethics-of-artificial-intelligence)
* [ProPublica series on Machine Bias](https://www.propublica.org/series/machine-bias)
* [Artificial Intelligence’s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html)
* [Neural Net Trained on Mugshots Predicts Criminals](https://www.technologyreview.com/s/602955/neural-network-learns-to-identify-criminals-by-their-faces/)
* [Attacking discrimination with smarter machine learning](http://research.google.com/bigpicture/attacking-discrimination-in-ml/)
* [The Ethical Data Scientis](http://www.slate.com/articles/technology/future_tense/2016/02/how_to_bring_better_ethics_to_data_science.html)
* [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
* [Machine Bias - How We Analyzed the COMPAS Recidivism Algorithm](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)
* [ProPublica Responds to Company’s Critique of Machine Bias Story](https://www.propublica.org/article/propublica-responds-to-companys-critique-of-machine-bias-story)
* [Are Machines Biased, or Are We Biased Against Machines?](http://alex.miller.im/posts/are-we-biased-against-machines-propublica-recidivism/)
* [Artificial Intelligence’s White Guy Problem](http://www.nytimes.com/2016/06/26/opinion/sunday/artificial-intelligences-white-guy-problem.html)
* [Buyer Beware: A hard look at police ‘threat scores.’](https://www.equalfuture.us/2016/01/14/buyer-beware-police-threat-scores/)
* [Computer and Information Ethics](http://plato.stanford.edu/entries/ethics-computer/)
* [Social Networking and Ethics](http://plato.stanford.edu/entries/ethics-social-networking/)
* [Internet Research Ethics](http://plato.stanford.edu/entries/ethics-internet-research/)
* [Search Engines and Ethics](http://plato.stanford.edu/entries/ethics-search/)
* [How a Machine Learns Prejudice](https://www.scientificamerican.com/article/how-a-machine-learns-prejudice/)
* [Courts Are Using AI to Sentence Criminals. That Must Stop Now](https://www.wired.com/2017/04/courts-using-ai-sentence-criminals-must-stop-now/)
* [Sent to Prison by a Software Program’s Secret Algorithms](https://www.nytimes.com/2017/05/01/us/politics/sent-to-prison-by-a-software-programs-secret-algorithms.html)
* [Even artificial intelligence can acquire biases against race and gender](http://www.sciencemag.org/news/2017/04/even-artificial-intelligence-can-acquire-biases-against-race-and-gender)
* [Inspecting Algorithms for Bias](https://www.technologyreview.com/s/607955/inspecting-algorithms-for-bias/)
* [If you’re not a white male, artificial intelligence’s use in healthcare could be dangerous](https://qz.com/1023448/if-youre-not-a-white-male-artificial-intelligences-use-in-healthcare-could-be-dangerous/)
* [Biased Algorithms Are Everywhere, and No One Seems to Care](https://www.technologyreview.com/s/608248/biased-algorithms-are-everywhere-and-no-one-seems-to-care/)
* [Turns Out Algorithms Are Racist](https://newrepublic.com/article/144644/turns-algorithms-racist)
* [Machines Taught by Photos Learn a Sexist View of Women](https://www.wired.com/story/machines-taught-by-photos-learn-a-sexist-view-of-women/)
* [How Tech Giants Are Devising Real Ethics for Artificial Intelligence](https://www.nytimes.com/2016/09/02/technology/artificial-intelligence-ethics.html)
* [New AI can guess whether you're gay or straight from a photograph](https://www.theguardian.com/technology/2017/sep/07/new-artificial-intelligence-can-tell-whether-youre-gay-or-straight-from-a-photograph)

## Others
* [Machine ethics: The robot’s dilemma](http://www.nature.com/news/machine-ethics-the-robot-s-dilemma-1.17881)
* [Morals and the machine](http://www.economist.com/node/21556234)
* [Robotics: Ethics of artificial intelligence](http://www.nature.com/news/robotics-ethics-of-artificial-intelligence-1.17611)
* [Do no harm, don't discriminate: official guidance issued on robot ethics](https://www.theguardian.com/technology/2016/sep/18/official-guidance-robot-ethics-british-standards-institute)
* ["RoboCop” assignment Columbia University NYPD’s “Stop, Question and Frisk” records](http://columbialion.com/colorcode-statement-on-coms-4771-stop-and-frisk-competition/)
* [Professor Satyen Kale Responds to ‘RoboCop’ Machine Learning Assignment](http://columbialion.com/professor-satyen-kale-responds-to-robocop-ml-assignment/)
* [White House document: Preparing for the Future of Artificial Intelligence](https://www.whitehouse.gov/sites/default/files/whitehouse_files/microsites/ostp/NSTC/preparing_for_the_future_of_ai.pdf)
* [Justice.exe - Educative Game](http://justiceexe.com/index.html)
* [mathwashing](http://www.mathwashing.com/)
* [ConceptNet Numberbatch 17.04: better, less-stereotyped word vectors](https://blog.conceptnet.io/2017/04/24/conceptnet-numberbatch-17-04-better-less-stereotyped-word-vectors/)

## Reports
* [ARTIFICIAL INTELLIGENCE AND LIFE IN 2030 - 2016 Report](https://ai100.stanford.edu/2016-report)

## Conferences, Workshops, Symposiums 

* [Workshop on Fairness, Accountability, and Transparency in Machine Learning](http://www.fatml.org/)
* [AI Now](https://artificialintelligencenow.com/schedule/2017-symposium)
* [Ethics of Artificial Intelligence](https://wp.nyu.edu/consciousness/ethics-of-artificial-intelligence/)

## Classes

* [Fairness in Machine Learning](https://fairmlclass.github.io/)


## People and Organizations

* [Kate Crawford](http://www.katecrawford.net/)
* [Meredith Whittaker](https://twitter.com/mer__edith)
* [Kate Darling](https://twitter.com/grok_)
* [Cathy O'Neil](https://mathbabe.org/)
* [Alan Winfield](https://alanwinfield.blogspot.com/)
* [AI Now](https://artificialintelligencenow.com/)
* [Algorithm Watch](https://algorithmwatch.org)
* [Moritz Hardt](http://moritzhardt.com/)
* [Institute for Ethics and Emerging Technologies](https://ieet.org/)

